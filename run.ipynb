{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-renganayaki7104/Contribute/blob/main/run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "eaRQ-jebFlBp"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Spr-Aachen/Easy-Voice-Toolkit/blob/main/run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "2cx_Ry_yFlCF"
      },
      "source": [
        "## Terms of Use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "8CtkMMYBFlCI"
      },
      "source": [
        "**Please solve the authorization problem of the dataset on your own. You shall be solely responsible for any problems caused by the use of non-authorized datasets for training and all consequences thereof.The repository and its maintainer have nothing to do with the consequences!**\n",
        "\n",
        "1. This project is established for academic exchange purposes only and is intended for communication and learning purposes. It is not intended for production environments.\n",
        "2. Any videos based on Easy Voice Toolkit that are published on video platforms must clearly indicate in the description that they are used for voice changing and specify the input source of the voice or audio, for example, using videos or audios published by others and separating the vocals as input source for conversion, which must provide clear original video links. If your own voice or other synthesized voices from other commercial vocal synthesis software are used as the input source for conversion, you must also explain it in the description.\n",
        "3. You shall be solely responsible for any infringement problems caused by the input source. When using other commercial vocal synthesis software as input source, please ensure that you comply with the terms of use of the software. Note that many vocal synthesis engines clearly state in their terms of use that they cannot be used for input source conversion.\n",
        "4. Continuing to use this project is deemed as agreeing to the relevant provisions stated in this repository README. This repository README has the obligation to persuade, and is not responsible for any subsequent problems that may arise.\n",
        "5. If you distribute this repository's code or publish any results produced by this project publicly (including but not limited to video sharing platforms), please indicate the original author and code source (this repository).\n",
        "6. If you use this project for any other plan, please contact and inform the author of this repository in advance. Thank you very much."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1vKaJCCNF9n7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcNuE7JzFlCS"
      },
      "source": [
        "## Configure Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWQk0HSFFlCV"
      },
      "source": [
        "### 防止断连<br>Prevent Disconnection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EblwyDLicmnp"
      },
      "source": [
        "按住 Ctrl+Shift 再按下 I 呼出浏览器的开发工具，于控制台内输入以下内容并回车\n",
        "```\n",
        "function ConnectButton()\n",
        "{\n",
        "    console.log(\"Connect pushed\");\n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
        "}\n",
        "setInterval(ConnectButton,60000);\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNE-NStQFlCc"
      },
      "source": [
        "### 使用GPU<br>Use GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AClKVwGqFlCg"
      },
      "source": [
        "找到上方菜单栏“代码执行程序”——>“更改运行时类型”——>\"硬件加速器\"，选择GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyJeSM7-FlCi"
      },
      "source": [
        "### 克隆仓库<br>Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mi8e00AaFlCl",
        "outputId": "59d614e3-03c2-44e8-b749-71d7b95ed314",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Easy-Voice-Toolkit'...\n",
            "remote: Enumerating objects: 2053, done.\u001b[K\n",
            "remote: Counting objects: 100% (133/133), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 2053 (delta 37), reused 41 (delta 30), pack-reused 1920 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2053/2053), 7.66 MiB | 11.01 MiB/s, done.\n",
            "Resolving deltas: 100% (1247/1247), done.\n",
            "Submodule 'EVT_Core/AudioProcessor' (https://github.com/Spr-Aachen/EVT-Core-AudioProcessor) registered for path 'EVT_Core/AudioProcessor'\n",
            "Submodule 'EVT_Core/GPT-SoVITS' (https://github.com/Spr-Aachen/EVT-Core-GPT-SoVITS) registered for path 'EVT_Core/GPT_SoVITS'\n",
            "Submodule 'EVT_Core/VITS' (https://github.com/Spr-Aachen/EVT-Core-VITS) registered for path 'EVT_Core/VITS'\n",
            "Submodule 'EVT_Core/VPR' (https://github.com/Spr-Aachen/EVT-Core-VPR) registered for path 'EVT_Core/VPR'\n",
            "Submodule 'EVT_Core/Whisper' (https://github.com/Spr-Aachen/EVT-Core-Whisper) registered for path 'EVT_Core/Whisper'\n",
            "Cloning into '/content/Easy-Voice-Toolkit/Easy-Voice-Toolkit/EVT_Core/AudioProcessor'...\n",
            "remote: Enumerating objects: 60, done.        \n",
            "remote: Counting objects: 100% (60/60), done.        \n",
            "remote: Compressing objects: 100% (39/39), done.        \n",
            "remote: Total 60 (delta 20), reused 56 (delta 19), pack-reused 0 (from 0)        \n",
            "Receiving objects: 100% (60/60), 31.12 KiB | 3.46 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n",
            "Cloning into '/content/Easy-Voice-Toolkit/Easy-Voice-Toolkit/EVT_Core/GPT_SoVITS'...\n",
            "remote: Enumerating objects: 205, done.        \n",
            "remote: Counting objects: 100% (205/205), done.        \n",
            "remote: Compressing objects: 100% (163/163), done.        \n",
            "remote: Total 205 (delta 50), reused 184 (delta 32), pack-reused 0 (from 0)        \n",
            "Receiving objects: 100% (205/205), 5.94 MiB | 9.88 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "Cloning into '/content/Easy-Voice-Toolkit/Easy-Voice-Toolkit/EVT_Core/VITS'...\n",
            "remote: Enumerating objects: 63, done.        \n",
            "remote: Counting objects: 100% (63/63), done.        \n",
            "remote: Compressing objects: 100% (50/50), done.        \n",
            "remote: Total 63 (delta 14), reused 58 (delta 11), pack-reused 0 (from 0)        \n",
            "Receiving objects: 100% (63/63), 55.31 KiB | 5.53 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n",
            "Cloning into '/content/Easy-Voice-Toolkit/Easy-Voice-Toolkit/EVT_Core/VPR'...\n",
            "remote: Enumerating objects: 20, done.        \n",
            "remote: Counting objects: 100% (20/20), done.        \n",
            "remote: Compressing objects: 100% (16/16), done.        \n",
            "remote: Total 20 (delta 4), reused 15 (delta 2), pack-reused 0 (from 0)        \n",
            "Receiving objects: 100% (20/20), 9.65 KiB | 9.65 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Cloning into '/content/Easy-Voice-Toolkit/Easy-Voice-Toolkit/EVT_Core/Whisper'...\n",
            "remote: Enumerating objects: 35, done.        \n",
            "remote: Counting objects: 100% (35/35), done.        \n",
            "remote: Compressing objects: 100% (31/31), done.        \n",
            "remote: Total 35 (delta 1), reused 32 (delta 1), pack-reused 0 (from 0)        \n",
            "Receiving objects: 100% (35/35), 1.12 MiB | 3.53 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Submodule path 'EVT_Core/AudioProcessor': checked out 'd8580328d7da40256fedd55e59f7fe5049b1850e'\n",
            "Submodule path 'EVT_Core/GPT_SoVITS': checked out '209ac8e98bbe625f6fd18d237d7a66fe4c312f8d'\n",
            "Submodule path 'EVT_Core/VITS': checked out 'd9f5fa8a34325f653b211796103af237f4ce5c05'\n",
            "Submodule path 'EVT_Core/VPR': checked out 'ac5368115db925123c07dc823eb5715f7dc6a02f'\n",
            "Submodule path 'EVT_Core/Whisper': checked out 'ece7fe6b2be791615ec18f5090dcebb886e39b4b'\n",
            "/content/Easy-Voice-Toolkit\n"
          ]
        }
      ],
      "source": [
        "!git clone --recurse-submodules https://github.com/Spr-Aachen/Easy-Voice-Toolkit.git\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "!sed -i '10s/False/True/' ./EVT_Core/GPT_SoVITS/config.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGtntNTIFlCr"
      },
      "source": [
        "### 安装依赖<br>Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umCkTdorFlCs",
        "outputId": "3febe32e-b7c2-47f9-c55f-c82da925c7bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,369 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,668 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,533 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,731 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,988 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [56.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,934 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,774 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [64.2 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,682 kB]\n",
            "Fetched 28.2 MB in 5s (6,200 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0\n",
            "Suggested packages:\n",
            "  portaudio19-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0 portaudio19-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 188 kB of archives.\n",
            "After this operation, 927 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
            "Fetched 188 kB in 0s (396 kB/s)\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 124947 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Ignoring onnxruntime: markers 'sys_platform == \"darwin\"' don't match your environment\n",
            "Ignoring opencc: markers 'sys_platform != \"linux\"' don't match your environment\n",
            "Collecting pydub (from -r requirements.txt (line 3))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.13.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.10.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
            "Collecting visualdl (from -r requirements.txt (line 8))\n",
            "  Downloading visualdl-2.5.3-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pyaudio (from -r requirements.txt (line 9))\n",
            "  Downloading PyAudio-0.2.14.tar.gz (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.5.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (10.6.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (4.48.3)\n",
            "Collecting ffmpeg-python (from -r requirements.txt (line 14))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting num2words (from -r requirements.txt (line 16))\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (6.0.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (0.60.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (3.10.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (4.25.6)\n",
            "Collecting onnxruntime-gpu (from -r requirements.txt (line 24))\n",
            "  Downloading onnxruntime_gpu-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (2.18.0)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (7.5.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (5.2.0)\n",
            "Collecting unidecode (from -r requirements.txt (line 28))\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langdetect (from -r requirements.txt (line 29))\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 30)) (0.2.0)\n",
            "Collecting wordsegment (from -r requirements.txt (line 31))\n",
            "  Downloading wordsegment-1.3.1-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (3.9.1)\n",
            "Collecting eng_to_ipa (from -r requirements.txt (line 33))\n",
            "  Downloading eng_to_ipa-0.0.2.tar.gz (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting g2p_en (from -r requirements.txt (line 34))\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting pypinyin (from -r requirements.txt (line 35))\n",
            "  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting jieba_fast (from -r requirements.txt (line 36))\n",
            "  Downloading jieba_fast-0.53.tar.gz (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cn2an (from -r requirements.txt (line 37))\n",
            "  Downloading cn2an-0.5.23-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pyjyutping (from -r requirements.txt (line 38))\n",
            "  Downloading pyjyutping-1.0.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting opencc==1.1.1 (from -r requirements.txt (line 40))\n",
            "  Downloading OpenCC-1.1.1-py2.py3-none-manylinux1_x86_64.whl.metadata (10 kB)\n",
            "Collecting python_mecab_ko (from -r requirements.txt (line 41))\n",
            "  Downloading python_mecab_ko-1.3.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting g2pk2 (from -r requirements.txt (line 42))\n",
            "  Downloading g2pk2-0.0.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting ko_pron (from -r requirements.txt (line 43))\n",
            "  Downloading ko_pron-1.3-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pyopenjtalk>=0.3.4 (from -r requirements.txt (line 44))\n",
            "  Downloading pyopenjtalk-0.4.0.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting LangSegment>=0.2.0 (from -r requirements.txt (line 45))\n",
            "  Downloading LangSegment-0.3.5-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio<=4.24.0,>=4.0 (from -r requirements.txt (line 46))\n",
            "  Downloading gradio-4.24.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting modelscope==1.10.0 (from -r requirements.txt (line 47))\n",
            "  Downloading modelscope-1.10.0-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting PyQt5 (from -r requirements.txt (line 48))\n",
            "  Downloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting addict (from modelscope==1.10.0->-r requirements.txt (line 47))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 47)) (25.1.0)\n",
            "Collecting datasets>=2.14.5 (from modelscope==1.10.0->-r requirements.txt (line 47))\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 47)) (0.8.1)\n",
            "Requirement already satisfied: filelock>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 47)) (3.17.0)\n",
            "Requirement already satisfied: gast>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 47)) (0.6.0)\n",
            "Collecting oss2 (from modelscope==1.10.0->-r requirements.txt (line 47))\n",
            "  Downloading oss2-2.19.1.tar.gz (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 47)) (2.2.2)\n",
            "Requirement already satisfied: Pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 47)) (11.1.0)\n",
            "Requirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 47)) (18.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 47)) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 47)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 47)) (75.1.0)\n",
            "Collecting simplejson>=3.3.0 (from modelscope==1.10.0->-r requirements.txt (line 47))\n",
            "  Downloading simplejson-3.20.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: sortedcontainers>=1.5.9 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 47)) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 47)) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.10.0->-r requirements.txt (line 47)) (2.3.0)\n",
            "Collecting yapf (from modelscope==1.10.0->-r requirements.txt (line 47))\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile->-r requirements.txt (line 4)) (1.17.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.1.0)\n",
            "Collecting bce-python-sdk (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading bce_python_sdk-0.9.29-py3-none-any.whl.metadata (416 bytes)\n",
            "Requirement already satisfied: flask>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from visualdl->-r requirements.txt (line 8)) (3.1.0)\n",
            "Collecting Flask-Babel>=3.0.0 (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading flask_babel-4.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from visualdl->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from visualdl->-r requirements.txt (line 8)) (24.2)\n",
            "Collecting rarfile (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from visualdl->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 13)) (0.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 13)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 13)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 13)) (0.5.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python->-r requirements.txt (line 14)) (1.0.0)\n",
            "Collecting docopt>=0.6.2 (from num2words->-r requirements.txt (line 16))\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->-r requirements.txt (line 19)) (0.43.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 21)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 21)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 21)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 21)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 21)) (3.2.1)\n",
            "Collecting coloredlogs (from onnxruntime-gpu->-r requirements.txt (line 24))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu->-r requirements.txt (line 24)) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu->-r requirements.txt (line 24)) (1.13.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 25)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 25)) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 25)) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 25)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 25)) (3.1.3)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect->-r requirements.txt (line 26)) (4.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->-r requirements.txt (line 32)) (8.1.8)\n",
            "Collecting distance>=0.1.3 (from g2p_en->-r requirements.txt (line 34))\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting proces>=0.1.7 (from cn2an->-r requirements.txt (line 37))\n",
            "  Downloading proces-0.1.7-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting python-mecab-ko-dic (from python_mecab_ko->-r requirements.txt (line 41))\n",
            "  Downloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting jamo (from g2pk2->-r requirements.txt (line 42))\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting py3langid>=0.2.2 (from LangSegment>=0.2.0->-r requirements.txt (line 45))\n",
            "  Downloading py3langid-0.3.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (5.5.0)\n",
            "Collecting fastapi (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46))\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46))\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==0.14.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46))\n",
            "  Downloading gradio_client-0.14.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (3.10.15)\n",
            "Collecting Pillow>=6.2.0 (from modelscope==1.10.0->-r requirements.txt (line 47))\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (2.10.6)\n",
            "Collecting python-multipart>=0.0.9 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46))\n",
            "  Downloading ruff-0.9.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.9 in /usr/local/lib/python3.11/dist-packages (from typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (0.15.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 46))\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==0.14.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (2024.10.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.14.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46))\n",
            "  Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting PyQt5-sip<13,>=12.15 (from PyQt5->-r requirements.txt (line 48))\n",
            "  Downloading PyQt5_sip-12.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (472 bytes)\n",
            "Collecting PyQt5-Qt5<5.16.0,>=5.15.2 (from PyQt5->-r requirements.txt (line 48))\n",
            "  Downloading PyQt5_Qt5-5.15.16-1-py3-none-manylinux2014_x86_64.whl.metadata (536 bytes)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (1.29.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 4)) (2.22)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 47))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 47))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 47))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 47)) (3.11.13)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (1.9.0)\n",
            "Requirement already satisfied: Babel>=2.12 in /usr/local/lib/python3.11/dist-packages (from Flask-Babel>=3.0.0->visualdl->-r requirements.txt (line 8)) (2.17.0)\n",
            "Requirement already satisfied: pytz>=2022.7 in /usr/local/lib/python3.11/dist-packages (from Flask-Babel>=3.0.0->visualdl->-r requirements.txt (line 8)) (2025.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (0.14.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->modelscope==1.10.0->-r requirements.txt (line 47)) (2025.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 5)) (4.3.6)\n",
            "INFO: pip is looking at multiple versions of py3langid to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting py3langid>=0.2.2 (from LangSegment>=0.2.0->-r requirements.txt (line 45))\n",
            "  Downloading py3langid-0.2.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25->modelscope==1.10.0->-r requirements.txt (line 47)) (3.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa->-r requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (13.9.4)\n",
            "\u001b[33mWARNING: typer 0.15.2 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pycryptodome>=3.8.0 (from bce-python-sdk->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu->-r requirements.txt (line 24))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46))\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting crcmod>=1.7 (from oss2->modelscope==1.10.0->-r requirements.txt (line 47))\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2->modelscope==1.10.0->-r requirements.txt (line 47))\n",
            "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2->modelscope==1.10.0->-r requirements.txt (line 47))\n",
            "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu->-r requirements.txt (line 24)) (1.3.0)\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope==1.10.0->-r requirements.txt (line 47))\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope==1.10.0->-r requirements.txt (line 47)) (43.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 47)) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 47)) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 47)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 47)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 47)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 47)) (1.18.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (0.23.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (2.18.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 46)) (0.1.2)\n",
            "Downloading OpenCC-1.1.1-py2.py3-none-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.10.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading visualdl-2.5.3-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime_gpu-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wordsegment-1.3.1-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cn2an-0.5.23-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyjyutping-1.0.0-py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.7/143.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_mecab_ko-1.3.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (580 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m580.9/580.9 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading g2pk2-0.0.3-py3-none-any.whl (25 kB)\n",
            "Downloading ko_pron-1.3-py3-none-any.whl (12 kB)\n",
            "Downloading LangSegment-0.3.5-py3-none-any.whl (28 kB)\n",
            "Downloading gradio-4.24.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.14.0-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.4/312.4 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_babel-4.0.0-py3-none-any.whl (9.6 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading proces-0.1.7-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py3langid-0.2.2-py3-none-any.whl (750 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyQt5_Qt5-5.15.16-1-py3-none-manylinux2014_x86_64.whl (61.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyQt5_sip-12.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.whl (276 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading simplejson-3.20.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading bce_python_sdk-0.9.29-py3-none-any.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.6/343.6 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl (34.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pyaudio, langdetect, eng_to_ipa, jieba_fast, pyopenjtalk, distance, docopt, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaudio: filename=pyaudio-0.2.14-cp311-cp311-linux_x86_64.whl size=67393 sha256=bc4c8b3ec25fd0c6f7055d57c3d925bac3e54626be5ab9ced64c3e7e4dbb813e\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/b1/c1/67e4ef443de2665d86031d4760508094eab5de37d5d64d9c27\n"
          ]
        }
      ],
      "source": [
        "!apt-get update``\n",
        "!apt-get install portaudio19-dev\n",
        "!pip3 install -r requirements.txt\n",
        "#!pip3 install --force-reinstall --yes torch torchvision torchaudio\n",
        "!/usr/local/bin/pip install ipykernel\n",
        "'''\n",
        "!apt-get install python3.9\n",
        "!cp -r /usr/local/lib/python3.10/dist-packages /usr/local/lib/python3.9/\n",
        "'''\n",
        "#exit() # Enable this only when you decide to delete the runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08EnGpCPFlCt"
      },
      "source": [
        "### 下载模型<br>Download Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZKFxJPFFlCu"
      },
      "outputs": [],
      "source": [
        "# get UVR5 models\n",
        "!mkdir -p /content/models/download/uvr5\n",
        "%cd /content/models/download/uvr5\n",
        "!git clone https://huggingface.co/Delik/uvr5_weights\n",
        "!mv /content/models/download/uvr5/uvr5_weights/* /content/models/download/uvr5/\n",
        "# get VPR models\n",
        "!mkdir -p /content/models/download/VPR\n",
        "%cd /content/models/download/VPR\n",
        "!git clone https://huggingface.co/SprAachen/VPR\n",
        "!mv /content/models/download/VPR/VPR/* /content/models/download/VPR\n",
        "# get Whisper models\n",
        "!mkdir -p /content/models/download/Whisper\n",
        "%cd /content/models/download/Whisper\n",
        "!git clone https://huggingface.co/SprAachen/Whisper\n",
        "!mv /content/models/download/Whisper/Whisper/* /content/models/download/Whisper\n",
        "# get GPT-SoVITS pretrains\n",
        "!mkdir -p /content/models/download/GPT-SoVITS\n",
        "%cd /content/models/download/GPT-SoVITS\n",
        "!git clone https://huggingface.co/lj1995/GPT-SoVITS\n",
        "!mv /content/models/download/GPT-SoVITS/GPT-SoVITS/* /content/models/download/GPT-SoVITS/\n",
        "# get VITS pretrains\n",
        "# **暂无，抱歉 Not Available**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21eu02OYFlCx"
      },
      "source": [
        "### 装载硬盘<br>Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7uAD30lFlCz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mygh_hGFlC0"
      },
      "source": [
        "### 准备文件<br>Prepare Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGITSh5kFlC1"
      },
      "source": [
        "检查是否已将需要处理的文件上传到了 https://drive.google.com/drive/my-drive 中"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2BFiJTUFlC2"
      },
      "source": [
        "## Run Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hetVR9FjFlC4"
      },
      "source": [
        "### 音频处理 AudioProcessor\n",
        "将媒体文件批量转换为音频文件然后自动切除音频的静音部分"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mog4pLtYFlC5"
      },
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.AudioProcessor.Process import Audio_Processing\n",
        "\n",
        "#@markdown **媒体输入目录**：需要输出为音频文件的媒体文件的目录\n",
        "Media_Dir_Input: str = '/content/drive/MyDrive/%MediaInput%'   #@param {type:\"string\"}\n",
        "#@markdown **媒体输出格式**：需要输出为的音频文件的格式\n",
        "Media_Format_Output: str = 'wav'   #@param [\"flac\", \"wav\", \"mp3\", \"aac\", \"ogg\", \"m4a\", \"wma\", \"aiff\", \"au\"]\n",
        "#@markdown **启用降噪**：音频中的噪声将被降噪处理\n",
        "Denoise_Audio: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **降噪目标**：选择在降噪时要保留的声音对象\n",
        "Denoise_Target: str = '人声'   #@param [\"人声\", \"背景声\"]\n",
        "#@markdown **启用静音切除**：音频中的静音部分将被切除\n",
        "Slice_Audio: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **均方根阈值 (db)**：低于该阈值的片段将被视作静音进行处理，若有降噪需求可以增加该值\n",
        "RMS_Threshold: float = -40.   #@param {type:\"number\"}\n",
        "#@markdown **跳跃大小 (ms)**：每个RMS帧的长度，增加该值能够提高分割精度但会减慢进程\n",
        "Hop_Size: int = 10   #@param {type:\"integer\"}\n",
        "#@markdown **最小静音间隔 (ms)**：静音部分被分割成的最小长度，若音频只包含短暂中断可以减小该值（注意：这个值必须小于 Audio Length Min，大于 Hop Size）\n",
        "Silent_Interval_Min: int = 300   #@param {type:\"integer\"}\n",
        "#@markdown **最大静音长度 (ms)**：被分割的音频周围保持静音的最大长度（提示：这个值无需完全对应被分割音频中的静音长度。算法将自行检索最佳的分割位置）\n",
        "Silence_Kept_Max: int = 1000   #@param {type:\"integer\"}\n",
        "#@markdown **最小音频长度 (ms)**：每个被分割的音频片段所需的最小长度\n",
        "Audio_Length_Min: int = 3000   #@param {type:\"integer\"}\n",
        "#@markdown **输出采样率**：输出音频所拥有的采样率，若维持不变则保持'None'即可\n",
        "SampleRate: int = None   #@param [\"None\", 44100, 48000, 96000, 192000]\n",
        "#@markdown **输出采样位数**：输出音频所拥有的采样位数，若维持不变则保持'None'即可\n",
        "SampleWidth: int = None   #@param [\"None\", 8, 16, 24, 32]\n",
        "#@markdown **合并声道**：将输出音频的声道合并为单声道\n",
        "ToMono: bool = False   #@param {type:\"boolean\"}\n",
        "#@markdown **输出目录**：用于保存最后生成的音频文件的目录\n",
        "Media_Dir_Output: str = f'/content/drive/MyDrive/EVT/音频处理结果/{date.today()}'   #@param {type:\"string\"}\n",
        "\n",
        "AudioConvertandSlice = Audio_Processing(\n",
        "    Media_Dir_Input,\n",
        "    Media_Format_Output,\n",
        "    SampleRate if SampleRate != \"None\" else None,\n",
        "    SampleWidth if SampleWidth != \"None\" else None,\n",
        "    ToMono,\n",
        "    Denoise_Audio,\n",
        "    '/content/models/download/uvr5/HP5_only_main_vocal.pth',\n",
        "    Denoise_Target,\n",
        "    Slice_Audio,\n",
        "    RMS_Threshold,\n",
        "    Audio_Length_Min,\n",
        "    Silent_Interval_Min,\n",
        "    Hop_Size,\n",
        "    Silence_Kept_Max,\n",
        "    Path(Media_Dir_Output).parent.__str__(),\n",
        "    Path(Media_Dir_Output).name\n",
        ")\n",
        "AudioConvertandSlice.Process_Audio()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJMZqHJwFlC7"
      },
      "source": [
        "### 语音识别 VoiceIdentifier\n",
        "在不同说话人的音频中批量筛选出属于同一说话人的音频"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_my3fNZFlC8"
      },
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.VPR.Identify import Voice_Identifying\n",
        "\n",
        "#@markdown **音频输入目录**：需要进行语音识别筛选的音频文件的目录\n",
        "Audio_Dir_Input: str = '/content/drive/MyDrive/%...%'   #@param {type:\"string\"}\n",
        "#@markdown **目标人物与音频**：目标人物的名字及其语音文件的所在路径\n",
        "StdAudioSpeaker: dict = {'%SpeakerName%': '/content/drive/MyDrive/%StdAudio.wav%'}   #@param {type:\"raw\"}\n",
        "#@markdown **判断阈值**：判断是否为同一人的阈值，若参与比对的说话人声音相识度较高可以增加该值\n",
        "DecisionThreshold: float = 0.75   #@param {type:\"number\"}\n",
        "#@markdown **音频长度**：用于预测的音频长度\n",
        "Duration_of_Audio: float = 3.00   #@param {type:\"number\"}\n",
        "#@markdown **输出目录**：用于保存最后生成的结果文件的目录\n",
        "Output_Dir: str = f'/content/drive/MyDrive/EVT/语音识别结果/{date.today()}'   #@param {type:\"string\"}\n",
        "#@markdown **识别结果文本名**：用于保存最后生成的记录音频文件与对应说话人的txt文件的名字\n",
        "AudioSpeakersDataName: str = 'Recgonition'   #@param {type:\"string\"}\n",
        "\n",
        "import os, shutil\n",
        "def ASRResult_Update(AudioSpeakersData_Path: str, MoveToDst: str):\n",
        "    os.makedirs(MoveToDst, exist_ok = True) if Path(MoveToDst).exists() == False else None\n",
        "    with open(AudioSpeakersData_Path, mode = 'w', encoding = 'utf-8') as AudioSpeakersData:\n",
        "        AudioSpeakers = AudioSpeakersData.readlines()\n",
        "        Lines = []\n",
        "        for AudioSpeaker in AudioSpeakers:\n",
        "            Audio, Speaker = AudioSpeaker.split('|', maxsplit = 1)\n",
        "            if Speaker.strip() != '':\n",
        "                MoveToDst_Sub = Path(MoveToDst).joinpath(Speaker).as_posix()\n",
        "                os.makedirs(MoveToDst_Sub, exist_ok = True) if Path(MoveToDst_Sub).exists() == False else None\n",
        "                Audio_Dst = Path(MoveToDst_Sub).joinpath(Path(Audio).name).as_posix()\n",
        "                shutil.copy(Audio, MoveToDst_Sub) if not Path(Audio_Dst).exists() else None\n",
        "                Lines.append(f\"{Audio_Dst}|{Speaker}\\n\")\n",
        "        AudioSpeakersData.writelines(Lines)\n",
        "\n",
        "AudioContrastInference = Voice_Identifying(\n",
        "    StdAudioSpeaker,\n",
        "    Audio_Dir_Input,\n",
        "    '/content/models/download/VPR/Ecapa-Tdnn_spectrogram.pth',\n",
        "    'Ecapa-Tdnn',\n",
        "    'spectrogram',\n",
        "    DecisionThreshold,\n",
        "    Duration_of_Audio,\n",
        "    Path(Output_Dir).parent.__str__(),\n",
        "    Path(Output_Dir).name,\n",
        "    AudioSpeakersDataName\n",
        ")\n",
        "AudioContrastInference.GetModel()\n",
        "AudioContrastInference.Inference()\n",
        "ASRResult_Update(\n",
        "    Path(Output_Dir).joinpath(AudioSpeakersDataName) + \".txt\",\n",
        "    Output_Dir\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jod-JoLjFlC9"
      },
      "source": [
        "### 语音转录 VoiceTranscriber\n",
        "将语音文件的内容批量转换为带时间戳的文本并以字幕文件的形式保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLiclA3zFlC-"
      },
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.Whisper.Transcribe import Voice_Transcribing\n",
        "\n",
        "#@markdown **音频目录**：需要将语音内容转为文字的wav文件的目录\n",
        "Audio_Dir: str = '/content/drive/MyDrive/%EVT/语音识别结果/...%'   #@param {type:\"string\"}\n",
        "#@markdown **标注语言信息**：标注音频中说话人所使用的语言，若用于VITS数据集制作则建议启用\n",
        "Add_LanguageInfo: str = True   #@param {type:\"boolean\"}\n",
        "#@markdown **半精度训练**：主要使用半精度浮点数进行计算，若GPU不可用则忽略或禁用此项\n",
        "fp16: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **启用输出日志**：是否输出debug日志\n",
        "Verbose: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **关联上下文**：在音频之间的内容具有关联性时启用该项可以获得更好的效果，若模型陷入了失败循环则禁用此项\n",
        "Condition_on_Previous_Text: bool = False   #@param {type:\"boolean\"}\n",
        "#@markdown **输出目录**：最后生成的字幕文件将会保存到该目录中\n",
        "Output_Dir: str = f'/content/drive/MyDrive/EVT/语音转录结果/{date.today()}'   #@param {type:\"string\"}\n",
        "\n",
        "WAVtoSRT = Voice_Transcribing(\n",
        "    '/content/models/download/Whisper/base.pt',\n",
        "    Audio_Dir,\n",
        "    Verbose,\n",
        "    Add_LanguageInfo,\n",
        "    Condition_on_Previous_Text,\n",
        "    fp16,\n",
        "    Path(Output_Dir).parent.__str__(),\n",
        "    Path(Output_Dir).name\n",
        ")\n",
        "WAVtoSRT.Transcriber()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hgk3wcTFlC_"
      },
      "source": [
        "### GPT-SoVITS数据集制作 DatasetCreator - GPT-SoVITS\n",
        "生成适用于语音模型训练的数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_m07fhmFlDA"
      },
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.GPT_SoVITS.Create import Dataset_Creating\n",
        "\n",
        "#@markdown **音频文件目录/语音识别结果文件路径**：音频文件的所在目录（要求按说话人分类），或者提供由语音识别得到的文本文件的所在路径\n",
        "AudioSpeakersData_Path: str = '/content/drive/MyDrive/%EVT/语音识别结果/GPT-SoVITS/...%'   #@param {type:\"string\"}\n",
        "#@markdown **字幕输入目录**：需要转为适用于模型训练的csv文件的srt文件的目录\n",
        "SRT_Dir: str = '/content/drive/MyDrive/%EVT/语音转录结果/GPT-SoVITS/...%'   #@param {type:\"string\"}\n",
        "#@markdown **输出目录**：用于保存最后生成的数据集的目录\n",
        "Output_Dir: str = f'/content/drive/MyDrive/EVT/数据集制作结果/GPT-SoVITS/{date.today()}'   #@param {type:\"string\"}\n",
        "#@markdown **训练集文本名**：用于保存最后生成的训练集txt文件的名字\n",
        "FileList_Name_Training: str = 'Train'   #@param {type:\"string\"}\n",
        "\n",
        "SRTtoCSVandSplitAudio = Dataset_Creating(\n",
        "    SRT_Dir = SRT_Dir,\n",
        "    AudioSpeakersData_Path = AudioSpeakersData_Path,\n",
        "    Output_Root = Path(Output_Dir).parent.__str__(),\n",
        "    Output_DirName = Path(Output_Dir).name,\n",
        "    FileList_Name = FileList_Name_Training\n",
        ")\n",
        "SRTtoCSVandSplitAudio.CallingFunctions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cka3qE0cFlDE"
      },
      "source": [
        "### GPT-SoVITS模型训练 VoiceTrainer - GPT-SoVITS\n",
        "训练出适用于语音合成的模型文件（若在使用过程中出现报错，可以尝试先`断开连接并删除运行时`，然后重新运行 Configure Colab 部分以及本代码块）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVuOG9wkFlDF"
      },
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.GPT_SoVITS.Train import Train\n",
        "\n",
        "#@markdown **训练集文本路径**：用于提供训练集音频路径及其语音内容的训练集txt文件的路径\n",
        "FileList_Path: str = '/content/drive/MyDrive/%EVT/数据集制作结果/GPT-SoVITS/Train.txt%'   #@param {type:\"string\"}\n",
        "#@markdown **半精度训练**：通过混合了float16精度的训练方式减小显存占用以支持更大的批处理量\n",
        "FP16_Run: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **输出目录**：用于存放生成的模型和配置文件的目录，若目录中已存在模型则会将其视为检查点（注意：当目录中存在多个模型时，编号最大的会被选为检查点）\n",
        "Output_Dir: str = f'/content/drive/MyDrive/EVT/模型训练结果/GPT-SoVITS/{date.today()}'   #@param {type:\"string\"}\n",
        "\n",
        "PreprocessandTrain = Train(\n",
        "    FileList_Path,\n",
        "    FP16_Run,\n",
        "    Model_Dir_Pretrained_bert = '/content/models/download/GPT-SoVITS/chinese-roberta-wwm-ext-large',\n",
        "    Model_Dir_Pretrained_ssl = '/content/models/download/GPT-SoVITS/chinese-hubert-base',\n",
        "    Model_Path_Pretrained_s1 = '/content/models/download/GPT-SoVITS/s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt',\n",
        "    Model_Path_Pretrained_s2G = '/content/models/download/GPT-SoVITS/s2G488k.pth',\n",
        "    Model_Path_Pretrained_s2D = '/content/models/download/GPT-SoVITS/s2D488k.pth',\n",
        "    Output_Root = Path(Output_Dir).parent.__str__(),\n",
        "    Output_DirName = Path(Output_Dir).name,\n",
        "    Output_LogDir = \"/content/drive/MyDrive/EVT/log\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVnK14oeFlDH"
      },
      "source": [
        "### GPT-SoVITS语音合成 VoiceConverter - GPT-SoVITS\n",
        "将文字转为语音并生成音频文件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XG-eAWo3FlDI"
      },
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.GPT_SoVITS.Convert import Convert\n",
        "\n",
        "#@markdown **半精度推理**：通过混合了float16精度的推理方式减小显存占用以支持更大的批处理量\n",
        "FP16_Run: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **启用批处理推理**：通过批处理推理的方式减小显存占用以支持更大的批处理量\n",
        "Enable_Batched_Infer: bool = True   #@param {type:\"boolean\"}\n",
        "\n",
        "VoiceConverting = Convert(\n",
        "    Model_Path_Load_s1 = '/content/models/download/GPT-SoVITS/s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt',\n",
        "    Model_Path_Load_s2G = '/content/models/download/GPT-SoVITS/s2G488k.pth',\n",
        "    Model_Dir_Load_bert = '/content/models/download/GPT-SoVITS/chinese-roberta-wwm-ext-large',\n",
        "    Model_Dir_Load_ssl = '/content/models/download/GPT-SoVITS/chinese-hubert-base',\n",
        "    Set_FP16_Run = FP16_Run,\n",
        "    Enable_Batched_Infer = Enable_Batched_Infer,\n",
        "    Use_WebUI = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UQBCaUCFlDK"
      },
      "source": [
        "### VITS2数据集制作 DatasetCreator - VITS2\n",
        "生成适用于语音模型训练的数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIPeONHPFlDL"
      },
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.VITS.Create import Dataset_Creating\n",
        "\n",
        "#@markdown **音频文件目录/语音识别结果文件路径**：音频文件的所在目录（要求按说话人分类），或者提供由语音识别得到的文本文件的所在路径\n",
        "AudioSpeakersData_Path: str = '/content/drive/MyDrive/%EVT/语音识别结果/VITS/...%'   #@param {type:\"string\"}\n",
        "#@markdown **字幕输入目录**：需要转为适用于模型训练的csv文件的srt文件的目录\n",
        "SRT_Dir: str = '/content/drive/MyDrive/%EVT/语音转录结果/VITS/...%'   #@param {type:\"string\"}\n",
        "#@markdown **添加辅助数据**：添加用以辅助训练的数据集，若当前语音数据的质量/数量较低则建议启用\n",
        "Add_AuxiliaryData: bool = False   #@param {type:\"boolean\"}\n",
        "#@markdown **辅助数据文本路径**：辅助数据集的文本的所在路径\n",
        "AuxiliaryData_Path: str = '/content/drive/MyDrive/%EVT/AuxiliaryData/VITS/AuxiliaryData.txt%'   #@param {type:\"string\"}\n",
        "#@markdown **添加其它语言辅助数据**：启用以允许添加与当前数据集语言不匹配的辅助数据\n",
        "Add_UnmatchedLanguage: bool = False   #@param {type:\"boolean\"}\n",
        "#@markdown **采样率 (HZ)**：数据集所要求的音频采样率，若维持不变则保持'None'即可\n",
        "SampleRate: int = 22050   #@param [\"None\", 22050, 44100, 48000, 96000, 192000]\n",
        "#@markdown **采样位数**：数据集所要求的音频采样位数，若维持不变则保持'None'即可\n",
        "SampleWidth: str = '16'   #@param [\"None\", 8, 16, 24, 32]\n",
        "#@markdown **合并声道**：将输出音频的声道合并为单声道\n",
        "ToMono: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **训练集占比**：划分给训练集的数据在数据集中所占的比例\n",
        "TrainRatio: float = 0.7   #@param {type:\"number\"}\n",
        "#@markdown **输出目录**：用于保存最后生成的数据集的目录\n",
        "Output_Dir: str = f'/content/drive/MyDrive/EVT/数据集制作结果/VITS/{date.today()}'   #@param {type:\"string\"}\n",
        "#@markdown **训练集文本名**：用于保存最后生成的训练集txt文件的名字\n",
        "FileList_Name_Training: str = 'Train'   #@param {type:\"string\"}\n",
        "#@markdown **验证集文本名**：用于保存最后生成的验证集txt文件的名字\n",
        "FileList_Name_Validation: str = 'Val'   #@param {type:\"string\"}\n",
        "\n",
        "SRTtoCSVandSplitAudio = Dataset_Creating(\n",
        "    SRT_Dir,\n",
        "    AudioSpeakersData_Path,\n",
        "    SampleRate if SampleRate != \"None\" else None,\n",
        "    SampleWidth if SampleWidth != \"None\" else None,\n",
        "    ToMono,\n",
        "    Add_AuxiliaryData,\n",
        "    AuxiliaryData_Path,\n",
        "    Add_UnmatchedLanguage,\n",
        "    TrainRatio,\n",
        "    Path(Output_Dir).parent.__str__(),\n",
        "    Path(Output_Dir).name,\n",
        "    FileList_Name_Training,\n",
        "    FileList_Name_Validation\n",
        ")\n",
        "SRTtoCSVandSplitAudio.CallingFunctions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eCt-O5ZFlDM"
      },
      "source": [
        "### VITS2模型训练 VoiceTrainer - VITS2\n",
        "训练出适用于语音合成的模型文件（若在使用过程中出现报错，可以尝试先`断开连接并删除运行时`，然后重新运行 Configure Colab 部分以及本代码块）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYn0yq3JFlDN"
      },
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.VITS.Train import Train\n",
        "\n",
        "#@markdown **训练集文本路径**：用于提供训练集音频路径及其语音内容的训练集txt文件的路径\n",
        "FileList_Path_Training: str = '/content/drive/MyDrive/%EVT/数据集制作结果/VITS/Train.txt%'   #@param {type:\"string\"}\n",
        "#@markdown **验证集文本路径**：用于提供验证集音频路径及其语音内容的验证集txt文件的路径\n",
        "FileList_Path_Validation: str = '/content/drive/MyDrive/%EVT/数据集制作结果/VITS/Val.txt%'   #@param {type:\"string\"}\n",
        "#@markdown **迭代次数**：将全部样本完整迭代一轮的次数\n",
        "Epochs: int = 300   #@param {type:\"integer\"}\n",
        "#@markdown **批处理量**：每轮迭代中单位批次的样本数量（注意：最好设置为2的幂次）\n",
        "Batch_Size: int = 16   #@param {type:\"integer\"}\n",
        "#@markdown **使用预训练模型**：使用预训练模型（底模），注意其载入优先级高于检查点\n",
        "Use_PretrainedModels: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **[可选]预训练G模型路径**：预训练生成器（Generator）模型的路径\n",
        "Model_Path_Pretrained_G: str = '/content/drive/MyDrive/%EVT/Pretrained Models/standard_G.pth%'   #@param {type:\"string\"}\n",
        "#@markdown **[可选]预训练D模型路径**：预训练判别器（Discriminator）模型的路径\n",
        "Model_Path_Pretrained_D: str = '/content/drive/MyDrive/%EVT/Pretrained Models/standard_D.pth%'   #@param {type:\"string\"}\n",
        "#@markdown **[可选]保留原说话人**：保留底模中原有的说话人，请保证每个原角色至少有一两条音频参与训练\n",
        "Keep_Original_Speakers: bool = False   #@param {type:\"boolean\"}\n",
        "#@markdown **[可选]配置加载路径**：用于加载底模人物信息的配置文件的所在路径\n",
        "Config_Path_Load: str = '/content/drive/MyDrive/%EVT/Pretrained Models/standard_Config.json%'   #@param {type:\"string\"}\n",
        "#@markdown **进程数量**：进行数据加载时可并行的进程数量\n",
        "Num_Workers: int = 8   #@param {type:\"integer\"}\n",
        "#@markdown **半精度训练**：通过混合了float16精度的训练方式减小显存占用以支持更大的批处理量\n",
        "FP16_Run: bool = True   #@param {type:\"boolean\"}\n",
        "#@markdown **评估间隔**：每次保存模型所间隔的step数\n",
        "Eval_Interval: int = 1000   #@param {type:\"integer\"}\n",
        "#@markdown **输出目录**：用于存放生成的模型和配置文件的目录，若目录中已存在模型则会将其视为检查点（注意：当目录中存在多个模型时，编号最大的会被选为检查点）\n",
        "Output_Dir: str = f'/content/drive/MyDrive/EVT/模型训练结果/VITS/{date.today()}'   #@param {type:\"string\"}\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# Start TensorBoard\n",
        "%tensorboard --logdir /content/drive/MyDrive/EVT/TrainResult\n",
        "\n",
        "PreprocessandTrain = Train(\n",
        "    FileList_Path_Training,\n",
        "    FileList_Path_Validation,\n",
        "    Eval_Interval,\n",
        "    Epochs,\n",
        "    Batch_Size,\n",
        "    FP16_Run,\n",
        "    Keep_Original_Speakers,\n",
        "    Config_Path_Load,\n",
        "    Num_Workers,\n",
        "    Use_PretrainedModels,\n",
        "    Model_Path_Pretrained_G if Model_Path_Pretrained_G != \"None\" else None,\n",
        "    Model_Path_Pretrained_D if Model_Path_Pretrained_D != \"None\" else None,\n",
        "    Path(Output_Dir).parent.__str__(),\n",
        "    Path(Output_Dir).name,\n",
        "    \"/content/drive/MyDrive/EVT/log\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJV82hJnFlDP"
      },
      "source": [
        "### VITS2语音合成 VoiceConverter - VITS2\n",
        "将文字转为语音并生成音频文件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pg232iEJFlDP"
      },
      "outputs": [],
      "source": [
        "#@title Execute 运行\n",
        "%cd /content/Easy-Voice-Toolkit\n",
        "\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from EVT_Core.VITS.Convert import Convert\n",
        "\n",
        "#@markdown **配置加载路径**：该路径对应的配置文件会用于推理\n",
        "Config_Path_Load: str = '/content/drive/MyDrive/%EVT/模型训练结果/VITS/Config.json%'   #@param {type:\"string\"}\n",
        "#@markdown **G模型加载路径**：用于推理的生成器（Generator）模型所在路径\n",
        "Model_Path_Load: str = '/content/drive/MyDrive/%EVT/模型训练结果/VITS/G_*.pth%'   #@param {type:\"string\"}\n",
        "#@markdown **输入文字**：输入的文字会作为说话人的语音内容\n",
        "Text: str = '请输入语句'   #@param {type:\"string\"}\n",
        "#@markdown **所用语言**：说话人/文字所使用的语言，若使用自动检测则保持'None'即可\n",
        "Language: str = '[ZH]'   #@param [\"None\", \"[ZH]\", \"[EN]\", \"[JA]\"]\n",
        "#@markdown **人物名字**：说话人物的名字\n",
        "Speaker: str = '%Name%'   #@param {type:\"string\"}\n",
        "#@markdown **情感强度**：情感的变化程度\n",
        "EmotionStrength: float = .667   #@param {type:\"number\"}\n",
        "#@markdown **音素音长**：音素的发音长度\n",
        "PhonemeDuration: float = 0.8   #@param {type:\"number\"}\n",
        "#@markdown **整体语速**：整体的说话速度\n",
        "SpeechRate: float = 1.0   #@param {type:\"number\"}\n",
        "#@markdown **音频保存路径**：用于保存推理得到的音频的路径\n",
        "Audio_Path_Save: str = f'/content/drive/MyDrive/EVT/语音合成结果/VITS/{date.today()}.wav'   #@param {type:\"string\"}\n",
        "\n",
        "VoiceConverting = Convert(\n",
        "    Config_Path_Load,\n",
        "    Model_Path_Load,\n",
        "    Text,\n",
        "    Language,\n",
        "    Speaker,\n",
        "    EmotionStrength,\n",
        "    PhonemeDuration,\n",
        "    SpeechRate,\n",
        "    Audio_Path_Save\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "My_Env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "d638444b7179bdfc0dc1957817588c7007ff4b9946fa53f9cc2df304cc8f4127"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}